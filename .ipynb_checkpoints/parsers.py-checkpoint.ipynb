{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "################################################################################\n",
    "# PART #1\n",
    "################################################################################\n",
    "import string\n",
    "import json\n",
    "import pandas as pd\n",
    "import os\n",
    "\n",
    "def countWordsUnstructured(filename):\n",
    "    d = {}\n",
    "    for line in open(filename,'r'):\n",
    "        t = line.split(' ')\n",
    "        for i in t:\n",
    "            try:\n",
    "                d[i.strip(string.punctuation+':-.,\\n\\t').replace(\",\",\"\")]+=1 #I threw in the .replace due to some numbers with commas being counted as words. E.g. '3,000'\n",
    "            except:\n",
    "                d[i.strip(string.punctuation+':-.,\\n\\t').replace(\",\",\"\")]=1\n",
    "    return d\n",
    "    # This function should count the words in an unstructured text document\n",
    "    # Inputs: A file name (string)\n",
    "    # Outputs: A dictionary with the counts for each word\n",
    "    # +1 bonus point for removing punctuation from the wordcounts\n",
    "    \n",
    "# Test your part 1 code below.\n",
    "\n",
    "################################################################################\n",
    "# PART 2\n",
    "################################################################################\n",
    "    \n",
    "def generateSimpleCSV(targetfile, wordCounts): \n",
    "    try:\n",
    "        with open(targetfile,'a') as file:\n",
    "            file.write(\"Word,Count\\n\")\n",
    "            for key,value in wordCounts.items():\n",
    "                file.write(str(key)+\",\"+str(value)+'\\n')\n",
    "        file.close()\n",
    "\n",
    "    except:\n",
    "        print(\"You done messed up!\")\n",
    "    # This function should transform a dictionary containing word counts to a\n",
    "    # CSV file. The first row of the CSV should be a header noting: \n",
    "    # Word, Count\n",
    "    # Inputs: A word count list and a name for the target file\n",
    "    # Outputs: A new CSV file named targetfile containing the wordcount data\n",
    "    \n",
    "# Test your part 2 code below\n",
    "    \n",
    "################################################################################\n",
    "# PART 3\n",
    "################################################################################\n",
    "def countWordsMany(directory):  \n",
    "    d={}\n",
    "    #d2 =[countWordsUnstructured(file) for file in os.scandir(directory)]\n",
    "    d2 =[file.name for file in os.scandir(\"./\"+directory)]\n",
    "    for i in d2:\n",
    "        d[i]=countWordsUnstructured(directory+\"/\"+i)\n",
    "    return d\n",
    "    \n",
    "    # This function should create a dictionary of word count dictionaries\n",
    "    # The dictionary should have one dictionary per file in the directory\n",
    "    # Each entry in the dictionary should be a word count dictionary\n",
    "    # Inputs: A directory containing a set of text files\n",
    "    # Outputs: A dictionary containing a word count dictionary for each\n",
    "    #          text file in the directory\n",
    "    \n",
    "# Test your part 3 code below\n",
    "#t = countWordsMany(\"state-of-the-union-corpus-1989-2017\")\n",
    "#print(t)\n",
    "\n",
    "################################################################################\n",
    "# PART 4\n",
    "################################################################################\n",
    "def generateDirectoryCSV(wordCounts, targetfile):\n",
    "    with open (targetfile,'a') as file:\n",
    "        file.write(\"Filename,Word,Count\\n\")\n",
    "        for key,value in wordCounts.items():\n",
    "            for a,b in value.items():   \n",
    "                file.write(str(key)+\",\"+str(a)+\",\"+str(b)+'\\n')\n",
    "    file.close()\n",
    "    return\n",
    "    # This function should create a CSV containing the word counts generated in\n",
    "    # part 3 with the header: \n",
    "    # Filename, Word, Count\n",
    "    # Inputs: A word count dictionary and a name for the target file\n",
    "    # Outputs: A CSV file named targetfile containing the word count data\n",
    "    \n",
    "# Test your part 4 code below\n",
    "    \n",
    "################################################################################\n",
    "# PART 5\n",
    "################################################################################\n",
    "def generateJSONFile(wordCounts, targetfile): \n",
    "    with open(targetfile, 'w') as file:\n",
    "        json.dump(wordCounts,file,indent=4)\n",
    "    file.close()\n",
    "    return\n",
    "    # This function should create an containing the word counts generated in\n",
    "    # part 3. Architect your JSON file such that the hierarchy will allow\n",
    "    # the user to quickly navigate and compare word counts between files. \n",
    "    # Inputs: A word count dictionary and a name for the target file\n",
    "    # Outputs: An JSON file named targetfile containing the word count data\n",
    "    \n",
    "# Test your part 5 code below\n",
    "\n",
    "################################################################################\n",
    "# PART 6\n",
    "################################################################################\n",
    "def searchCSV(csvfile, word): \n",
    "    count=0\n",
    "    try:\n",
    "        df = pd.read_csv(csvfile)\n",
    "        df_word = df[df['Word']==word]\n",
    "        t = [x for x in df_word[df_word['Count']==df_word['Count'].max()].reset_index().Filename]\n",
    "        count = [x for x in df_word[df_word['Count']==df_word['Count'].max()].reset_index().Count]\n",
    "\n",
    "    except:\n",
    "        t=\"No file contained that word.\"\n",
    "    t+=count\n",
    "    print(\"Datapoints needed to compute: \"+str(len(df_word)))\n",
    "    return t\n",
    "    # This function should search a CSV file from part 4 and find the filename\n",
    "    # with the largest count of a specified word\n",
    "    # Inputs: A CSV file to search and a word to search for\n",
    "    # Outputs: The filename containing the highest count of the target word\n",
    "    \n",
    "def searchJSON(JSONfile, word): \n",
    "    with open(JSONfile, 'r') as file:\n",
    "        d = json.load(file)\n",
    "    t=0\n",
    "    length = 0\n",
    "    x=\"No file contained that word\"\n",
    "    for key,value in d.items():\n",
    "        length+=1\n",
    "        try:\n",
    "            if value[word]>t:\n",
    "                t=value[word]\n",
    "                x=[key]\n",
    "            elif value[word]==t:\n",
    "                x.append(key)\n",
    "        except:\n",
    "            pass\n",
    "    x.append(t)\n",
    "    print(\"Datapoints needed to compute: \"+str(length))\n",
    "    file.close()\n",
    "    return x\n",
    "    # This function should search a JSON file from part 5 and find the filename\n",
    "    # with the largest count of a specified word\n",
    "    # Inputs: An JSON file to search and a word to search for\n",
    "    # Outputs: The filename containing the highest count of the target word\n",
    "    \n",
    "# Test your part 6 code to find which file has the highest count of a given word\n",
    "\n",
    "# +1 bonus point for figuring out how many datapoints you had to process to \n",
    "# compute this value\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# PART 7\n",
    "################################################################################\n",
    "\n",
    "\n",
    "#In the starter code, you also now have additional data on different presidents. \n",
    "#Design a database schema that allows you to store this data with your word counts\n",
    "#from the State of the Union addresses. Make sure to consider how you would connect\n",
    "#between different tables, how to integrate all of the data from both sources, and \n",
    "#how to minimize the amount of redundant information (you should have no duplicate \n",
    "#information in your final design). \n",
    "\n",
    "#Table 1: sotu_word_counts\n",
    "#      Column 1 =  text “filename”\n",
    "#      Column 2 = text “word”\n",
    "#      Column 3 = integer “count”\n",
    "\n",
    "\n",
    "#Table 2: us_presidents\n",
    "#     Column 1 =  int ‘number’,\n",
    "#     Column 2 = date start\n",
    "#     Column 3 = date end \n",
    "#     Column 4 = varchar president\n",
    "#     Column 5 = varchar prior \n",
    "#     Column 6 = varchar party\n",
    "#     Column 7 = varchar vice\n",
    "\n",
    "# By combining these two tables together in this fashion, the database would have all of the information needed\n",
    "# without having any repeating or redundant information. Connections could be made between the tables by focusing\n",
    "# on president nnames or by years.\n",
    "\n",
    "\n",
    "################################################################################\n",
    "# PART 8\n",
    "################################################################################\n",
    "\n",
    "\n",
    "#Create a new database using Python as part of your parsers.py code that implements\n",
    "#this schema. The inputs to this function should be a database name.\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "#   import sqlite3\n",
    "#   conn = sqlite.connect(‘presidents.db’) # Set up a connection to db\n",
    "#   c = conn.cursor() # allow access with a mouse\n",
    "#   c.execute(‘’’CREATE TABLE sotu_word_counts (filename text, word text, count integer)’’’) # ask connected to execute sql command\n",
    "#   c.execute(‘’’CREATE TABLE us_presidents (number integer, start date, end date, president text, prior text, party text, vice text)’’’) # ask connected to execute sql command\n",
    "#   conn.commit() # save (commit) the changes\n",
    "#   conn.close() # Close the connection\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n",
    "\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
